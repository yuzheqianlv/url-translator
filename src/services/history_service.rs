use gloo_storage::{LocalStorage, Storage};
use crate::types::history::{HistoryEntry, HistoryFilter, HistorySortBy, HistoryEntryType, BatchDocumentInfo};
use std::collections::HashMap;
use flate2::write::GzEncoder;
use flate2::Compression;
use tar::Builder;

const HISTORY_STORAGE_KEY: &str = "translation_history";
const MAX_HISTORY_ENTRIES: usize = 100;

#[derive(Clone, Debug)]
pub struct HistoryService;

impl HistoryService {
    pub fn new() -> Self {
        Self
    }
    
    pub fn get_all_entries(&self) -> Result<Vec<HistoryEntry>, Box<dyn std::error::Error>> {
        match LocalStorage::get::<Vec<HistoryEntry>>(HISTORY_STORAGE_KEY) {
            Ok(entries) => Ok(entries),
            Err(_) => Ok(Vec::new()),
        }
    }
    
    pub fn add_entry(&self, entry: HistoryEntry) -> Result<(), Box<dyn std::error::Error>> {
        let mut entries = self.get_all_entries()?;
        
        // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒURLçš„æ¡ç›®
        if let Some(existing_index) = entries.iter().position(|e| e.url == entry.url) {
            // æ›´æ–°ç°æœ‰æ¡ç›®
            entries[existing_index] = entry;
        } else {
            // æ·»åŠ æ–°æ¡ç›®
            entries.insert(0, entry);
            
            // ä¿æŒå†å²è®°å½•æ•°é‡åœ¨é™åˆ¶å†…
            if entries.len() > MAX_HISTORY_ENTRIES {
                entries.truncate(MAX_HISTORY_ENTRIES);
            }
        }
        
        self.save_entries(&entries)
    }
    
    pub fn get_entry_by_id(&self, id: &str) -> Result<Option<HistoryEntry>, Box<dyn std::error::Error>> {
        let entries = self.get_all_entries()?;
        Ok(entries.into_iter().find(|entry| entry.id == id))
    }
    
    pub fn delete_entry(&self, id: &str) -> Result<(), Box<dyn std::error::Error>> {
        let mut entries = self.get_all_entries()?;
        entries.retain(|entry| entry.id != id);
        self.save_entries(&entries)
    }
    
    pub fn clear_history(&self) -> Result<(), Box<dyn std::error::Error>> {
        LocalStorage::delete(HISTORY_STORAGE_KEY);
        Ok(())
    }
    
    pub fn search_entries(
        &self,
        filter: &HistoryFilter,
        sort_by: &HistorySortBy,
    ) -> Result<Vec<HistoryEntry>, Box<dyn std::error::Error>> {
        let mut entries = self.get_all_entries()?;
        
        // åº”ç”¨è¿‡æ»¤å™¨
        if let Some(ref search_term) = filter.search_term {
            let search_lower = search_term.to_lowercase();
            entries.retain(|entry| {
                entry.title.to_lowercase().contains(&search_lower) ||
                entry.url.to_lowercase().contains(&search_lower) ||
                entry.translated_content.to_lowercase().contains(&search_lower)
            });
        }
        
        if let Some(ref source_lang) = filter.source_lang {
            entries.retain(|entry| entry.source_lang == *source_lang);
        }
        
        if let Some(ref target_lang) = filter.target_lang {
            entries.retain(|entry| entry.target_lang == *target_lang);
        }
        
        // åº”ç”¨æ’åº
        match sort_by {
            HistorySortBy::CreatedAtDesc => {
                entries.sort_by(|a, b| b.created_at.cmp(&a.created_at));
            }
            HistorySortBy::CreatedAtAsc => {
                entries.sort_by(|a, b| a.created_at.cmp(&b.created_at));
            }
            HistorySortBy::TitleAsc => {
                entries.sort_by(|a, b| a.title.cmp(&b.title));
            }
            HistorySortBy::TitleDesc => {
                entries.sort_by(|a, b| b.title.cmp(&a.title));
            }
            HistorySortBy::WordCountDesc => {
                entries.sort_by(|a, b| b.word_count.cmp(&a.word_count));
            }
            HistorySortBy::WordCountAsc => {
                entries.sort_by(|a, b| a.word_count.cmp(&b.word_count));
            }
        }
        
        Ok(entries)
    }
    
    pub fn get_statistics(&self) -> Result<HistoryStatistics, Box<dyn std::error::Error>> {
        let entries = self.get_all_entries()?;
        
        let total_entries = entries.len();
        let total_words = entries.iter().map(|e| e.word_count).sum();
        
        let mut language_pairs: HashMap<String, usize> = HashMap::new();
        let mut most_translated_domains: HashMap<String, usize> = HashMap::new();
        
        for entry in &entries {
            let pair = format!("{} -> {}", entry.source_lang, entry.target_lang);
            *language_pairs.entry(pair).or_insert(0) += 1;
            
            if let Ok(parsed_url) = web_sys::Url::new(&entry.url) {
                let hostname = parsed_url.hostname();
                if !hostname.is_empty() {
                    *most_translated_domains.entry(hostname).or_insert(0) += 1;
                }
            }
        }
        
        let most_used_language_pair = language_pairs
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(pair, _)| pair);
        
        let most_translated_domain = most_translated_domains
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(domain, _)| domain);
        
        Ok(HistoryStatistics {
            total_entries,
            total_words,
            most_used_language_pair,
            most_translated_domain,
        })
    }
    
    pub fn export_history(&self, format: ExportFormat) -> Result<String, Box<dyn std::error::Error>> {
        let entries = self.get_all_entries()?;
        
        match format {
            ExportFormat::Json => {
                serde_json::to_string_pretty(&entries)
                    .map_err(|e| format!("JSONåºåˆ—åŒ–å¤±è´¥: {}", e).into())
            }
            ExportFormat::Csv => {
                let mut csv = String::from("ID,URL,Title,Source Language,Target Language,Created At,Word Count\n");
                for entry in entries {
                    csv.push_str(&format!(
                        "{},{},{},{},{},{},{}\n",
                        entry.id,
                        entry.url,
                        entry.title.replace(",", ";"),
                        entry.source_lang,
                        entry.target_lang,
                        entry.created_at,
                        entry.word_count
                    ));
                }
                Ok(csv)
            }
            ExportFormat::Markdown => {
                let mut md = String::from("# ç¿»è¯‘å†å²è®°å½•\n\n");
                for entry in entries {
                    md.push_str(&format!(
                        "## {}\n\n**URL**: {}\n\n**è¯­è¨€**: {} -> {}\n\n**åˆ›å»ºæ—¶é—´**: {}\n\n**å­—æ•°**: {}\n\n---\n\n",
                        entry.title,
                        entry.url,
                        entry.source_lang,
                        entry.target_lang,
                        entry.get_formatted_date(),
                        entry.word_count
                    ));
                }
                Ok(md)
            }
        }
    }
    
    /// ä¸‹è½½å•é¡µç¿»è¯‘è®°å½•
    pub fn download_single_page(&self, entry_id: &str) -> Result<Vec<u8>, String> {
        let entry = self.get_entry_by_id(entry_id)
            .map_err(|e| format!("è·å–è®°å½•å¤±è´¥: {}", e))?
            .ok_or("æœªæ‰¾åˆ°æŒ‡å®šè®°å½•".to_string())?;
        
        match entry.entry_type {
            HistoryEntryType::SinglePage => {
                let mut content = String::new();
                
                // æ·»åŠ æ–‡æ¡£å¤´éƒ¨ä¿¡æ¯
                content.push_str(&format!("# {}\n\n", entry.title));
                content.push_str(&format!("> **åŸå§‹URL**: {}\n", entry.url));
                content.push_str(&format!("> **ç¿»è¯‘æ—¶é—´**: {}\n", entry.get_formatted_date()));
                content.push_str(&format!("> **è¯­è¨€**: {} -> {}\n", entry.source_lang, entry.target_lang));
                content.push_str(&format!("> **å­—æ•°**: {} å­—\n\n", entry.word_count));
                content.push_str("---\n\n");
                
                // æ·»åŠ ç¿»è¯‘å†…å®¹
                content.push_str(&entry.translated_content);
                
                Ok(content.into_bytes())
            }
            HistoryEntryType::BatchTranslation => {
                Err("è¯¥è®°å½•æ˜¯æ‰¹é‡ç¿»è¯‘ï¼Œè¯·ä½¿ç”¨æ‰¹é‡ä¸‹è½½åŠŸèƒ½".to_string())
            }
        }
    }
    
    /// ä¸‹è½½æ‰¹é‡ç¿»è¯‘è®°å½•
    pub fn download_batch_translation(&self, entry_id: &str, selected_docs: Option<Vec<usize>>) -> Result<Vec<u8>, String> {
        let entry = self.get_entry_by_id(entry_id)
            .map_err(|e| format!("è·å–è®°å½•å¤±è´¥: {}", e))?
            .ok_or("æœªæ‰¾åˆ°æŒ‡å®šè®°å½•".to_string())?;
        
        match entry.entry_type {
            HistoryEntryType::BatchTranslation => {
                let batch_data = entry.batch_data.as_ref()
                    .ok_or("æ‰¹é‡ç¿»è¯‘æ•°æ®ç¼ºå¤±".to_string())?;
                
                // ç¡®å®šè¦ä¸‹è½½çš„æ–‡æ¡£
                let docs_to_download: Vec<&BatchDocumentInfo> = if let Some(selected_indices) = selected_docs {
                    selected_indices.iter()
                        .filter_map(|&index| batch_data.document_list.get(index))
                        .collect()
                } else {
                    batch_data.document_list.iter().filter(|doc| doc.translated).collect()
                };
                
                if docs_to_download.is_empty() {
                    return Err("æ²¡æœ‰é€‰ä¸­ä»»ä½•æ–‡æ¡£".to_string());
                }
                
                // åˆ›å»ºtar.gzå½’æ¡£
                self.create_batch_archive(&entry, &docs_to_download)
            }
            HistoryEntryType::SinglePage => {
                Err("è¯¥è®°å½•æ˜¯å•é¡µç¿»è¯‘ï¼Œè¯·ä½¿ç”¨å•é¡µä¸‹è½½åŠŸèƒ½".to_string())
            }
        }
    }
    
    /// åˆ›å»ºæ‰¹é‡ç¿»è¯‘çš„tar.gzå½’æ¡£
    fn create_batch_archive(&self, entry: &HistoryEntry, documents: &[&BatchDocumentInfo]) -> Result<Vec<u8>, String> {
        let tar_data = Vec::new();
        let encoder = GzEncoder::new(tar_data, Compression::default());
        let mut tar = Builder::new(encoder);
        
        // æ·»åŠ README.mdæ–‡ä»¶
        let readme_content = self.generate_batch_readme(entry, documents);
        let readme_bytes = readme_content.as_bytes();
        let mut header = tar::Header::new_gnu();
        header.set_size(readme_bytes.len() as u64);
        header.set_mode(0o644);
        header.set_cksum();
        
        tar.append_data(&mut header, "README.md", std::io::Cursor::new(readme_bytes))
            .map_err(|e| format!("æ— æ³•æ·»åŠ READMEæ–‡ä»¶: {}", e))?;
        
        // æŒ‰é¡ºåºæ·»åŠ æ–‡æ¡£
        for doc in documents {
            if !doc.translated {
                continue; // è·³è¿‡æœªç¿»è¯‘çš„æ–‡æ¡£
            }
            
            let file_path = if doc.folder_path.is_empty() || doc.folder_path == "docs" {
                format!("{:03}_{}", doc.order + 1, doc.file_name)
            } else {
                format!("{}/{:03}_{}", doc.folder_path, doc.order + 1, doc.file_name)
            };
            
            // åˆ›å»ºæ–‡æ¡£å†…å®¹
            let mut file_content = String::new();
            file_content.push_str(&format!("# {}\n\n", doc.title));
            file_content.push_str(&format!("> **åŸå§‹URL**: {}\n", doc.url));
            file_content.push_str(&format!("> **ç¿»è¯‘æ—¶é—´**: {}\n", entry.get_formatted_date()));
            file_content.push_str(&format!("> **æ–‡æ¡£åºå·**: {}\n", doc.order + 1));
            file_content.push_str(&format!("> **è¯­è¨€**: {} -> {}\n\n", entry.source_lang, entry.target_lang));
            file_content.push_str("---\n\n");
            file_content.push_str(&doc.translated_content);
            
            let file_bytes = file_content.as_bytes();
            let mut header = tar::Header::new_gnu();
            header.set_size(file_bytes.len() as u64);
            header.set_mode(0o644);
            header.set_cksum();
            
            tar.append_data(&mut header, &file_path, std::io::Cursor::new(file_bytes))
                .map_err(|e| format!("æ— æ³•æ·»åŠ æ–‡ä»¶ {}: {}", file_path, e))?;
        }
        
        // å®Œæˆtarå½’æ¡£
        let encoder = tar.into_inner()
            .map_err(|e| format!("æ— æ³•å®Œæˆtarå½’æ¡£: {}", e))?;
        
        let compressed_data = encoder.finish()
            .map_err(|e| format!("æ— æ³•å®Œæˆgzipå‹ç¼©: {}", e))?;
        
        Ok(compressed_data)
    }
    
    /// ç”Ÿæˆæ‰¹é‡ç¿»è¯‘çš„READMEå†…å®¹
    fn generate_batch_readme(&self, entry: &HistoryEntry, documents: &[&BatchDocumentInfo]) -> String {
        let mut content = String::new();
        
        content.push_str("# æ‰¹é‡ç¿»è¯‘æ–‡æ¡£å½’æ¡£\n\n");
        content.push_str(&format!("**é¡¹ç›®åç§°**: {}\n", entry.title));
        content.push_str(&format!("**ç´¢å¼•URL**: {}\n", entry.url));
        content.push_str(&format!("**ç¿»è¯‘æ—¶é—´**: {}\n", entry.get_formatted_date()));
        content.push_str(&format!("**è¯­è¨€**: {} -> {}\n", entry.source_lang, entry.target_lang));
        content.push_str(&format!("**æ–‡æ¡£æ€»æ•°**: {} ä¸ª\n\n", documents.len()));
        
        if let Some(batch_data) = &entry.batch_data {
            content.push_str(&format!("**ç¿»è¯‘ç»Ÿè®¡**:\n"));
            content.push_str(&format!("- æ€»æ–‡æ¡£æ•°: {}\n", batch_data.total_documents));
            content.push_str(&format!("- æˆåŠŸç¿»è¯‘: {}\n", batch_data.successful_documents));
            content.push_str(&format!("- å¤±è´¥æ–‡æ¡£: {}\n\n", batch_data.failed_documents));
        }
        
        content.push_str("## æ–‡æ¡£ç›®å½•\n\n");
        
        // æŒ‰æ–‡ä»¶å¤¹åˆ†ç»„æ˜¾ç¤ºç›®å½•
        let mut folders: HashMap<String, Vec<&BatchDocumentInfo>> = HashMap::new();
        for doc in documents {
            folders.entry(doc.folder_path.clone())
                .or_insert_with(Vec::new)
                .push(doc);
        }
        
        for (folder, docs) in folders {
            if !folder.is_empty() && folder != "docs" {
                content.push_str(&format!("### ğŸ“ {}\n\n", folder));
            }
            
            for doc in docs {
                let file_name = if doc.folder_path.is_empty() || doc.folder_path == "docs" {
                    format!("{:03}_{}", doc.order + 1, doc.file_name)
                } else {
                    format!("{:03}_{}", doc.order + 1, doc.file_name)
                };
                
                content.push_str(&format!(
                    "- [{}]({})\n  - åŸå§‹URL: {}\n  - æ–‡ä»¶è·¯å¾„: {}/{}\n\n",
                    doc.title,
                    file_name,
                    doc.url,
                    if folder.is_empty() || folder == "docs" { "." } else { &folder },
                    file_name
                ));
            }
        }
        
        content.push_str("---\n\n");
        content.push_str("*æ­¤å½’æ¡£ç”±URLç¿»è¯‘å·¥å…·å†å²è®°å½•åŠŸèƒ½ç”Ÿæˆ*\n");
        
        content
    }
    
    fn save_entries(&self, entries: &[HistoryEntry]) -> Result<(), Box<dyn std::error::Error>> {
        LocalStorage::set(HISTORY_STORAGE_KEY, entries)
            .map_err(|e| format!("ä¿å­˜å†å²è®°å½•å¤±è´¥: {:?}", e).into())
    }
}

#[derive(Debug, Clone)]
pub struct HistoryStatistics {
    pub total_entries: usize,
    pub total_words: usize,
    pub most_used_language_pair: Option<String>,
    pub most_translated_domain: Option<String>,
}

#[derive(Debug, Clone)]
pub enum ExportFormat {
    Json,
    Csv,
    Markdown,
}